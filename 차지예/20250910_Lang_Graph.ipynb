{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea17106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ==============================================================\n",
    "#  ì•Œë ˆë¥´ê¸° ë¶„ì„ ì„œë¹„ìŠ¤ (OCR â†’ Regex â†’ RAG â†’ Zero-shot Fallback)\n",
    "#  + ì›ì¬ë£Œëª… ì„¹ì…˜ ì„±ë¶„ë³„ ì•Œë ˆë¥´ê¸° íŒì •í‘œ ìƒì„±\n",
    "# ==============================================================\n",
    "\n",
    "import os, io, json, re, logging, unicodedata\n",
    "from typing import List, Set, TypedDict\n",
    "try:\n",
    "    from typing import NotRequired\n",
    "except ImportError:\n",
    "    NotRequired = None\n",
    "\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a42f3dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ğŸš€ ì•Œë ˆë¥´ê¸° ë¶„ì„ ì„œë¹„ìŠ¤ (OCR + RAG + ZS-Fallback + per-ingredient) ì‹œì‘ ---\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s | %(message)s\")\n",
    "print(\"--- ğŸš€ ì•Œë ˆë¥´ê¸° ë¶„ì„ ì„œë¹„ìŠ¤ (OCR + RAG + ZS-Fallback + per-ingredient) ì‹œì‘ ---\")\n",
    "\n",
    "# --- í‘œì¤€ ì•Œë ˆë¥´ê¸° / í•„í„° / ë™ì˜ì–´ ---\n",
    "ALLERGENS_STD_SET = {\n",
    "    \"ì•Œë¥˜\", \"ìš°ìœ \", \"ë©”ë°€\", \"ë•…ì½©\", \"ëŒ€ë‘\", \"ë°€\", \"ì£\", \"í˜¸ë‘\",\n",
    "    \"ê²Œ\", \"ìƒˆìš°\", \"ì˜¤ì§•ì–´\", \"ê³ ë“±ì–´\", \"ì¡°ê°œë¥˜\", \"ë³µìˆ­ì•„\", \"í† ë§ˆí† \",\n",
    "    \"ë‹­ê³ ê¸°\", \"ë¼ì§€ê³ ê¸°\", \"ì‡ ê³ ê¸°\", \"ì•„í™©ì‚°ë¥˜\"\n",
    "}\n",
    "IGNORE_KEYWORDS = {\n",
    "    'ì—´ëŸ‰','íƒ„ìˆ˜í™”ë¬¼','ë‹¨ë°±ì§ˆ','ì§€ë°©','ë‹¹ë¥˜','ë‚˜íŠ¸ë¥¨','ì½œë ˆìŠ¤í…Œë¡¤','í¬í™”ì§€ë°©','íŠ¸ëœìŠ¤ì§€ë°©','ë‚´ìš©ëŸ‰','I','II'\n",
    "}\n",
    "ALIAS_MAP = {\n",
    "    # ì•Œë¥˜\n",
    "    \"ê³„ë€\":\"ì•Œë¥˜\",\"ë‹¬ê±€\":\"ì•Œë¥˜\",\"ë‚œë°±\":\"ì•Œë¥˜\",\"ë‚œí™©\":\"ì•Œë¥˜\",\n",
    "    # ìš°ìœ \n",
    "    \"ìœ ì²­\":\"ìš°ìœ \",\"ìœ ì²­ë¶„ë§\":\"ìš°ìœ \",\"ìœ ì²­ë‹¨ë°±\":\"ìš°ìœ \",\"ì¹´ì œì¸ë‚˜íŠ¸ë¥¨\":\"ìš°ìœ \",\"ì¹˜ì¦ˆ\":\"ìš°ìœ \",\"ë²„í„°\":\"ìš°ìœ \",\"í¬ë¦¼\":\"ìš°ìœ \",\"ë¶„ìœ \":\"ìš°ìœ \",\"íƒˆì§€ë¶„ìœ \":\"ìš°ìœ \",\n",
    "    # ëŒ€ë‘/ë°€/ë©”ë°€\n",
    "    \"ëŒ€ë‘ë ˆì‹œí‹´\":\"ëŒ€ë‘\",\"ëŒ€ë‘ë‹¨ë°±\":\"ëŒ€ë‘\",\"ì†Œì´í”„ë¡œí‹´\":\"ëŒ€ë‘\",\n",
    "    \"ë°€ê°€ë£¨\":\"ë°€\",\"ë©”ë°€ê°€ë£¨\":\"ë©”ë°€\",\n",
    "    # ìœ¡ë¥˜\n",
    "    \"ì†Œê³ ê¸°\":\"ì‡ ê³ ê¸°\",\"ì†Œ ìœ¡\":\"ì‡ ê³ ê¸°\",\"ìš°ìœ¡\":\"ì‡ ê³ ê¸°\",\"ë¼ì§€\":\"ë¼ì§€ê³ ê¸°\",\"ëˆìœ¡\":\"ë¼ì§€ê³ ê¸°\",\"ë‹­\":\"ë‹­ê³ ê¸°\",\"ê³„ìœ¡\":\"ë‹­ê³ ê¸°\",\n",
    "    # ê²¬ê³¼/ì–´íŒ¨ë¥˜ ë³€í˜•\n",
    "    \"í˜¸ë‘ë¶„ë§\":\"í˜¸ë‘\",\"ì£ê°€ë£¨\":\"ì£\",\"ìƒˆìš°ê°€ë£¨\":\"ìƒˆìš°\",\"ì˜¤ì§•ì–´ë¶„ë§\":\"ì˜¤ì§•ì–´\",\n",
    "    # ê³¼ì±„\n",
    "    \"í† ë§ˆí† í˜ì´ìŠ¤íŠ¸\":\"í† ë§ˆí† \"\n",
    "}\n",
    "def alias_to_std(name: str) -> str:\n",
    "    key = name.replace(\" \",\"\")\n",
    "    for k,v in ALIAS_MAP.items():\n",
    "        if k in key:\n",
    "            return v\n",
    "    return name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec90e8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | ì„ë² ë”© ëª¨ë¸ ë¡œë“œ: distiluse-base-multilingual-cased-v1\n",
      "INFO | Use pytorch device_name: cpu\n",
      "INFO | Load pretrained SentenceTransformer: distiluse-base-multilingual-cased-v1\n",
      "Device set to use cpu\n",
      "INFO | Zero-shot ëª¨ë¸ ì‚¬ìš©: MoritzLaurer/deberta-v3-large-zeroshot-v2.0 (device=-1)\n",
      "INFO | GCP Vision í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ\n",
      "INFO | KB ìºì‹œ ë¡œë“œ ì™„ë£Œ: 702ê°œ í•­ëª©\n"
     ]
    }
   ],
   "source": [
    "# --- ê¸€ë¡œë²Œ ë¦¬ì†ŒìŠ¤ ë¡œë“œ ---\n",
    "try:\n",
    "    EMBEDDING_MODEL_NAME = 'distiluse-base-multilingual-cased-v1'\n",
    "    logging.info(f\"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ: {EMBEDDING_MODEL_NAME}\")\n",
    "    embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "\n",
    "    ZSL_MODEL_CANDIDATES = [\n",
    "        \"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\",\n",
    "        \"joeddav/xlm-roberta-large-xnli\"\n",
    "    ]\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    nli_pipeline = None\n",
    "    for name in ZSL_MODEL_CANDIDATES:\n",
    "        try:\n",
    "            nli_pipeline = pipeline(\"zero-shot-classification\", model=name, device=device)\n",
    "            logging.info(f\"Zero-shot ëª¨ë¸ ì‚¬ìš©: {name} (device={device})\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"{name} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    if nli_pipeline is None:\n",
    "        logging.warning(\"Zero-shot ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ â†’ Fallback ë¹„í™œì„±\")\n",
    "\n",
    "    KEY_JSON_PATH_DEFAULT = r\"D:\\key folder\\ocr-project-470906-7ffeebabeb09.json\"  # í•„ìš”ì‹œ êµì²´\n",
    "    KEY_JSON_PATH = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\", KEY_JSON_PATH_DEFAULT)\n",
    "    vision_client = None\n",
    "    try:\n",
    "        credentials = service_account.Credentials.from_service_account_file(KEY_JSON_PATH)\n",
    "        vision_client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "        logging.info(\"GCP Vision í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"GCP Vision ì´ˆê¸°í™” ì‹¤íŒ¨: {e} â†’ ë¡œì»¬ OCR Fallbackë§Œ ì‚¬ìš©\")\n",
    "\n",
    "    KB_EMB_PATH = \"kb_embeddings.npy\"\n",
    "    KB_CAT_PATH = \"kb_categories.json\"\n",
    "    kb_embeddings = np.load(KB_EMB_PATH)\n",
    "    with open(KB_CAT_PATH,\"r\",encoding=\"utf-8\") as f:\n",
    "        kb_categories = json.load(f)\n",
    "    assert kb_embeddings.shape[0] == len(kb_categories), \\\n",
    "        f\"KB ë¶ˆì¼ì¹˜: emb={kb_embeddings.shape[0]} vs cat={len(kb_categories)}\"\n",
    "    logging.info(f\"KB ìºì‹œ ë¡œë“œ ì™„ë£Œ: {len(kb_categories)}ê°œ í•­ëª©\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"ê¸€ë¡œë²Œ ì„¤ì • ì‹¤íŒ¨: {e}\")\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0f22d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ì„ê³„ê°’/í…œí”Œë¦¿ ---\n",
    "RAG_CONFIDENCE_THRESHOLD = float(os.getenv(\"RAG_THRESHOLD\",\"0.85\"))\n",
    "NLI_FALLBACK_THRESHOLD   = float(os.getenv(\"NLI_THRESHOLD\",\"0.5\"))\n",
    "HYPOTHESIS = \"{} ì•Œë ˆë¥´ê¸°(ìœ ë°œ) ì„±ë¶„ì´ë‹¤.\"\n",
    "\n",
    "# --- ë¡œì»¬ OCR Fallback(ì˜µì…˜) ---\n",
    "def local_ocr_fallback(img_path: str) -> str:\n",
    "    try:\n",
    "        import easyocr\n",
    "        reader = easyocr.Reader(['ko','en'])\n",
    "        lines = reader.readtext(img_path, detail=0)\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67c496f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ìƒíƒœ ì •ì˜ (â˜… per-ingredient í•„ë“œ ì¶”ê°€) ---\n",
    "class AllergyGraphState(TypedDict):\n",
    "    image_path: str\n",
    "    raw_ocr_text: str\n",
    "    ingredients_to_check: deque\n",
    "    current_ingredient: str\n",
    "    rag_result: dict\n",
    "    final_allergens: Set[str]\n",
    "    final_output_json: str\n",
    "    # [ADDED] ì•„ë˜ 5ê°œ\n",
    "    ingredients_from_section: NotRequired[List[str]] if NotRequired else list  # ì›ì¬ë£Œëª… ëª©ë¡\n",
    "    declared_allergens: NotRequired[List[str]] if NotRequired else list        # '...í•¨ìœ ' ëª…ì‹œ ëª©ë¡(í‘œì¤€í™”)\n",
    "    coi_phrases: NotRequired[List[str]] if NotRequired else list               # êµì°¨ì˜¤ì—¼ ë¬¸êµ¬\n",
    "    per_ingredient_results: NotRequired[List[dict]] if NotRequired else list   # ì„±ë¶„ë³„ íŒì •í‘œ\n",
    "    current_raw_ingredient: NotRequired[str] if NotRequired else str           # ì›ë¬¸ ì„±ë¶„\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d6cb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ë…¸ë“œ ---\n",
    "\n",
    "def call_gcp_vision_api(state: AllergyGraphState) -> AllergyGraphState:\n",
    "    img_path = state['image_path']\n",
    "    logging.info(f\"[Node1] OCR í˜¸ì¶œ: {img_path}\")\n",
    "    text = \"\"\n",
    "    if vision_client is not None:\n",
    "        try:\n",
    "            with io.open(img_path,'rb') as f:\n",
    "                image = vision.Image(content=f.read())\n",
    "            res = vision_client.text_detection(image=image)\n",
    "            if res.error.message:\n",
    "                raise RuntimeError(res.error.message)\n",
    "            text = res.full_text_annotation.text or \"\"\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"GCP OCR ì‹¤íŒ¨: {e}\")\n",
    "    if not text.strip():\n",
    "        lt = local_ocr_fallback(img_path)\n",
    "        if lt.strip():\n",
    "            logging.info(\"ë¡œì»¬ OCR Fallback ì‚¬ìš©\")\n",
    "            text = lt\n",
    "    if not text.strip():\n",
    "        logging.warning(\"OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ\")\n",
    "    return {**state, \"raw_ocr_text\": text}\n",
    "\n",
    "def parse_text_from_raw(state: AllergyGraphState) -> AllergyGraphState:\n",
    "    \"\"\"[REPLACED] Regex íŒŒì„œ + ì›ì¬ë£Œëª…/í•¨ìœ /COI ë¶„ë¦¬ ìˆ˜ì§‘\"\"\"\n",
    "    raw_text = state.get('raw_ocr_text','') or ''\n",
    "    if not raw_text.strip():\n",
    "        return {**state, \"ingredients_to_check\": deque(), \"final_allergens\": set(),\n",
    "                \"ingredients_from_section\": [], \"declared_allergens\": [], \"coi_phrases\": [],\n",
    "                \"per_ingredient_results\": []}\n",
    "\n",
    "    text = unicodedata.normalize(\"NFKC\", raw_text).replace(\"\\n\",\" \")\n",
    "\n",
    "    # (1) ì›ì¬ë£Œëª… ë¸”ë¡\n",
    "    pat_ing = re.compile(\n",
    "        r\"ì›ì¬ë£Œ(?:ëª…| ë°[^:]{0,10}|/[^:]{0,10})?\\s*[:ï¼š]\\s*(.+?)(?:ì•Œë ˆë¥´ê¸°|ì˜ì–‘ì •ë³´|ì˜ì–‘ì„±ë¶„|í•¨ìœ |í’ˆëª©ë³´ê³ |ê³ ê°ìƒë‹´|ì†Œë¹„ê¸°í•œ|$)\",\n",
    "        re.S\n",
    "    )\n",
    "    ingredients_from_section: List[str] = []\n",
    "    m = pat_ing.search(text)\n",
    "    if m:\n",
    "        blob = m.group(1)\n",
    "        raw_items = [s.strip() for s in blob.split(',') if s.strip()]\n",
    "        cleaned = []\n",
    "        for it in raw_items:\n",
    "            it = it.split('(')[0].strip()\n",
    "            if any(it.startswith(k) for k in IGNORE_KEYWORDS):\n",
    "                continue\n",
    "            cleaned.append(it)\n",
    "        ingredients_from_section = cleaned\n",
    "        logging.info(f\"[Node2] ì›ì¬ë£Œ {len(cleaned)}ê°œ ì¶”ì¶œ: {cleaned[:12]}{'...' if len(cleaned)>12 else ''}\")\n",
    "    else:\n",
    "        logging.info(\"[Node2] ì›ì¬ë£Œëª… ë¸”ëŸ­ì„ ì°¾ì§€ ëª»í•¨\")\n",
    "\n",
    "    # (2) '...í•¨ìœ ' (ì•Œë ˆë¥´ê¸° ìœ ë°œë¬¼ì§ˆ: â€¦ í•¨ìœ  í¬í•¨)\n",
    "    pat_contains = re.compile(r\"(?:ì•Œë ˆë¥´ê¸°\\s*(?:ìœ ë°œ)?\\s*ë¬¼ì§ˆ[:ï¼š]?\\s*)?([ê°€-í£,\\s]+?)\\s*í•¨ìœ \")\n",
    "    declared_allergens = []\n",
    "    m2 = pat_contains.search(text)\n",
    "    if m2:\n",
    "        contains_list = [s.strip() for s in m2.group(1).split(',') if s.strip()]\n",
    "        logging.info(f\"[Node2] 'í•¨ìœ ' ì„¹ì…˜ {len(contains_list)}ê°œ: {contains_list}\")\n",
    "        # [ADDED] í‘œì¤€í™”(ë‹¬ê±€â†’ì•Œë¥˜ ë“±) + í‘œì¤€ ì§‘í•© í•„í„°\n",
    "        for item in contains_list:\n",
    "            std = alias_to_std(item)\n",
    "            if std in ALLERGENS_STD_SET:\n",
    "                declared_allergens.append(std)\n",
    "\n",
    "    # (3) COI(êµì°¨ì˜¤ì—¼) ë¬¸êµ¬ ì¶”ì¶œ\n",
    "    coi_phrases = []\n",
    "    for pat in [r\"ê°™ì€\\s*ì œì¡°(?:ì‹œì„¤|ë¼ì¸|ì„¤ë¹„)\", r\"êµì°¨ì˜¤ì—¼\", r\"í˜¼ì…\\s*ê°€ëŠ¥\", r\"í•¨ìœ \\s*ê°€ëŠ¥\"]:\n",
    "        for mm in re.finditer(pat, text):\n",
    "            s = max(0, text.rfind('.', 0, mm.start()))\n",
    "            e = text.find('.', mm.end())\n",
    "            coi_phrases.append(text[s+1:e if e!=-1 else mm.end()+30].strip())\n",
    "\n",
    "    # íëŠ” â€œì›ì¬ë£Œëª… ì„±ë¶„ë§Œâ€ ëŒ€ìƒìœ¼ë¡œ ë¶„ë¥˜ ë£¨í”„ ìˆ˜í–‰\n",
    "    q = deque(ingredients_from_section)\n",
    "\n",
    "    # ëª…ì‹œëœ ì•Œë ˆë¥´ê²ì€ ì¦‰ì‹œ ëˆ„ì (ìµœì¢…ì—ì„œ í•©ì§‘í•©)\n",
    "    found_set = set(declared_allergens)\n",
    "\n",
    "    return {**state,\n",
    "            \"ingredients_to_check\": q,\n",
    "            \"final_allergens\": found_set,\n",
    "            \"ingredients_from_section\": ingredients_from_section,\n",
    "            \"declared_allergens\": declared_allergens,\n",
    "            \"coi_phrases\": coi_phrases,\n",
    "            \"per_ingredient_results\": []}\n",
    "\n",
    "\n",
    "def prepare_next_ingredient(state: AllergyGraphState) -> AllergyGraphState:\n",
    "    \"\"\"[REPLACED] ë‹¤ìŒ ì„±ë¶„ ì¶”ì¶œ + alias í‘œì¤€í™” í•„ë“œ ìœ ì§€\"\"\"\n",
    "    q = state['ingredients_to_check']\n",
    "    if not q:\n",
    "        return state\n",
    "    raw = q.popleft()\n",
    "    std = alias_to_std(raw)\n",
    "    return {**state,\n",
    "            \"current_raw_ingredient\": raw,        # [ADDED]\n",
    "            \"current_ingredient\": std}            # ë¶„ë¥˜ëŠ” í‘œì¤€í™” í…ìŠ¤íŠ¸ ê¸°ì¤€\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33116941",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rag_search(state: AllergyGraphState) -> AllergyGraphState:\n",
    "    \"\"\"Node4: RAG (aliasê°€ ê³§ í‘œì¤€ ì•Œë ˆë¥´ê²ì´ë©´ ì¦‰ì‹œ í™•ì •)\"\"\"\n",
    "    ing_std = state.get('current_ingredient','')\n",
    "    ing_raw = state.get('current_raw_ingredient', ing_std)\n",
    "\n",
    "    # [ADDED] aliasë¡œ ê³§ë°”ë¡œ í‘œì¤€ ì•Œë ˆë¥´ê²ì´ ëœ ê²½ìš°: í™•ì •\n",
    "    if ing_std in ALLERGENS_STD_SET:\n",
    "        return {**state, \"rag_result\": {\"confidence\": 1.0, \"found_allergen\": ing_std, \"method\": \"alias\"}}\n",
    "\n",
    "    # ê·¸ ì™¸ì—ëŠ” RAG ê²€ìƒ‰\n",
    "    if not ing_std:\n",
    "        return {**state, \"rag_result\": {\"confidence\": 0.0, \"found_allergen\": \"ì—†ìŒ\", \"method\": \"none\"}}\n",
    "\n",
    "    qemb = embedding_model.encode([ing_std])\n",
    "    sims = cosine_similarity(qemb, kb_embeddings)\n",
    "    idx = int(np.argmax(sims[0])); conf = float(sims[0][idx]); found = kb_categories[idx]\n",
    "    logging.info(f\"[Node4] RAG: '{ing_raw}' â†’ '{found}' (sim={conf:.4f})\")\n",
    "    return {**state, \"rag_result\": {\"confidence\": conf, \"found_allergen\": found, \"method\": \"rag\"}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e17e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_fallback(state: AllergyGraphState) -> AllergyGraphState:\n",
    "    \"\"\"Node5: Zero-shot NLI\"\"\"\n",
    "    ing_std = state.get('current_ingredient','')\n",
    "    if not nli_pipeline or not ing_std:\n",
    "        return {**state, \"rag_result\": {\"confidence\": 1.0, \"found_allergen\": \"ì—†ìŒ\", \"method\": \"none\"}}\n",
    "    labels = list(ALLERGENS_STD_SET) + [\"ê´€ë ¨ ì—†ìŒ\"]\n",
    "    try:\n",
    "        resp = nli_pipeline(ing_std, labels, hypothesis_template=HYPOTHESIS)\n",
    "        top_label, top_score = resp['labels'][0], float(resp['scores'][0])\n",
    "        return {**state, \"rag_result\": {\n",
    "            \"confidence\": top_score,\n",
    "            \"found_allergen\": top_label if top_label in ALLERGENS_STD_SET and top_score>=NLI_FALLBACK_THRESHOLD else \"ì—†ìŒ\",\n",
    "            \"method\": \"nli\"\n",
    "        }}\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"[Node5] ZS ì˜¤ë¥˜: {e}\")\n",
    "        return {**state, \"rag_result\": {\"confidence\": 1.0, \"found_allergen\": \"ì—†ìŒ\", \"method\": \"none\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c214eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def update_final_list(state: AllergyGraphState) -> AllergyGraphState:\n",
    "    \"\"\"Node6: ê²°ê³¼ ì·¨í•© + â˜…ì„±ë¶„ë³„ íŒì •í‘œ ëˆ„ì  [CHANGED]\"\"\"\n",
    "    res = state['rag_result']\n",
    "    found = res.get(\"found_allergen\",\"ì—†ìŒ\")\n",
    "    conf  = float(res.get(\"confidence\",0.0))\n",
    "    method= res.get(\"method\",\"none\")\n",
    "\n",
    "    # 6-1) ìµœì¢… ì•Œë ˆë¥´ê² ì§‘í•©(ëª…ì‹œ + ì¶”ë¡ ) ëˆ„ì \n",
    "    cur_set = state['final_allergens']\n",
    "    if found in ALLERGENS_STD_SET:\n",
    "        cur_set.add(found)\n",
    "\n",
    "    # 6-2) â˜… ì„±ë¶„ë³„ íŒì •í‘œì— ë ˆì½”ë“œ ì¶”ê°€ (ì›ë¬¸/í‘œì¤€/ë°©ë²•/ì ìˆ˜/ì•Œë ˆë¥´ê²ì—¬ë¶€)\n",
    "    row = {\n",
    "        \"ingredient_raw\": state.get(\"current_raw_ingredient\", state.get(\"current_ingredient\",\"\")),\n",
    "        \"ingredient_std\": state.get(\"current_ingredient\",\"\"),\n",
    "        \"is_allergen\": found in ALLERGENS_STD_SET,\n",
    "        \"allergen\": found if found in ALLERGENS_STD_SET else \"ì—†ìŒ\",\n",
    "        \"method\": method,\n",
    "        \"confidence\": round(conf, 4)\n",
    "    }\n",
    "    table = state.get(\"per_ingredient_results\", [])\n",
    "    table.append(row)\n",
    "\n",
    "    return {**state, \"final_allergens\": cur_set, \"per_ingredient_results\": table}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd99899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_processing(state: AllergyGraphState) -> AllergyGraphState:\n",
    "    \"\"\"Node7: ì¢…ë£Œ (ëª…ì‹œí•¨ìœ  + ì¶”ë¡ í•©ì§‘í•©, COI, per-ingredient í¬í•¨)\"\"\"\n",
    "    inferred = set(state.get('final_allergens', set()))\n",
    "    declared = set(state.get('declared_allergens', []))\n",
    "    final_list = sorted(list(inferred.union(declared)))  # í•©ì§‘í•©\n",
    "\n",
    "    result = {\n",
    "        \"allergens\": final_list,\n",
    "        \"declared_allergens\": sorted(list(declared)),\n",
    "        \"coi_phrases\": state.get(\"coi_phrases\", []),\n",
    "        \"ingredients\": state.get(\"per_ingredient_results\", [])\n",
    "    }\n",
    "    final_json = json.dumps(result, ensure_ascii=False)\n",
    "    logging.info(f\"[DONE] {final_json}\")\n",
    "    return {**state, \"final_output_json\": final_json}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47a33255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ì¡°ê±´ë¶€ ì—£ì§€ ---\n",
    "def route_rag_result(state: AllergyGraphState) -> str:\n",
    "    conf = float(state['rag_result']['confidence'])\n",
    "    allergen = state['rag_result']['found_allergen']\n",
    "    if conf >= RAG_CONFIDENCE_THRESHOLD and allergen in ALLERGENS_STD_SET:\n",
    "        return \"rag_success\"\n",
    "    return \"needs_llm_fallback\"\n",
    "\n",
    "def check_remaining_ingredients(state: AllergyGraphState) -> str:\n",
    "    q = state.get(\"ingredients_to_check\", deque())\n",
    "    return \"has_more_ingredients\" if q and len(q)>0 else \"all_ingredients_done\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "871863a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | âœ… LangGraph ì»´íŒŒì¼ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# --- ê·¸ë˜í”„ ë¹Œë“œ/ì»´íŒŒì¼ ---\n",
    "workflow = StateGraph(AllergyGraphState)\n",
    "workflow.add_node(\"call_gcp_vision_api\", call_gcp_vision_api)\n",
    "workflow.add_node(\"parse_text_from_raw\", parse_text_from_raw)\n",
    "workflow.add_node(\"prepare_next_ingredient\", prepare_next_ingredient)\n",
    "workflow.add_node(\"rag_search\", rag_search)\n",
    "workflow.add_node(\"llm_fallback\", llm_fallback)\n",
    "workflow.add_node(\"update_final_list\", update_final_list)\n",
    "workflow.add_node(\"finalize_processing\", finalize_processing)\n",
    "\n",
    "workflow.set_entry_point(\"call_gcp_vision_api\")\n",
    "workflow.add_edge(\"call_gcp_vision_api\",\"parse_text_from_raw\")\n",
    "# [REPLACED] parse â†’ prepareë¥¼ ì¡°ê±´ë¶€ë¡œ (ë¹ˆ í ë³´í˜¸)\n",
    "workflow.add_conditional_edges(\n",
    "    \"parse_text_from_raw\",\n",
    "    check_remaining_ingredients,\n",
    "    {\"has_more_ingredients\":\"prepare_next_ingredient\",\"all_ingredients_done\":\"finalize_processing\"}\n",
    ")\n",
    "workflow.add_edge(\"prepare_next_ingredient\",\"rag_search\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"rag_search\",\n",
    "    route_rag_result,\n",
    "    {\"rag_success\":\"update_final_list\",\"needs_llm_fallback\":\"llm_fallback\"}\n",
    ")\n",
    "workflow.add_edge(\"llm_fallback\",\"update_final_list\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"update_final_list\",\n",
    "    check_remaining_ingredients,\n",
    "    {\"has_more_ingredients\":\"prepare_next_ingredient\",\"all_ingredients_done\":\"finalize_processing\"}\n",
    ")\n",
    "workflow.add_edge(\"finalize_processing\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "logging.info(\"âœ… LangGraph ì»´íŒŒì¼ ì™„ë£Œ\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07e1871c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | [Node1] OCR í˜¸ì¶œ: data/ê¹€ê´‘ë¬´_121.jpg\n",
      "INFO | [Node2] ì›ì¬ë£Œëª… ë¸”ëŸ­ì„ ì°¾ì§€ ëª»í•¨\n",
      "INFO | [Node2] 'í•¨ìœ ' ì„¹ì…˜ 5ê°œ: ['ë¼ì§€ê³ ê¸°', 'ëŒ€ë‘', 'ì‡ ê³ ê¸°', 'ë°€', 'ìš°ìœ ']\n",
      "INFO | [DONE] {\"allergens\": [\"ëŒ€ë‘\", \"ë¼ì§€ê³ ê¸°\", \"ë°€\", \"ì‡ ê³ ê¸°\", \"ìš°ìœ \"], \"declared_allergens\": [\"ëŒ€ë‘\", \"ë¼ì§€ê³ ê¸°\", \"ë°€\", \"ì‡ ê³ ê¸°\", \"ìš°ìœ \"], \"coi_phrases\": [\"ê°œ ê·¸ëŒ€ë¡œ ë„£ì„ ê²½ìš° í„°ì§ˆ ìš°ë ¤ê°€ ìˆìœ¼ë‹ˆ ì„ ì‚¬ìš©í•œ ì œí’ˆê³¼ ê°™ì€ ì œì¡°ì‹œì„¤ì—ì„œ ì œì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤\"], \"ingredients\": []}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ìµœì¢… ë°˜í™˜ JSON ===\n",
      "{\"allergens\": [\"ëŒ€ë‘\", \"ë¼ì§€ê³ ê¸°\", \"ë°€\", \"ì‡ ê³ ê¸°\", \"ìš°ìœ \"], \"declared_allergens\": [\"ëŒ€ë‘\", \"ë¼ì§€ê³ ê¸°\", \"ë°€\", \"ì‡ ê³ ê¸°\", \"ìš°ìœ \"], \"coi_phrases\": [\"ê°œ ê·¸ëŒ€ë¡œ ë„£ì„ ê²½ìš° í„°ì§ˆ ìš°ë ¤ê°€ ìˆìœ¼ë‹ˆ ì„ ì‚¬ìš©í•œ ì œí’ˆê³¼ ê°™ì€ ì œì¡°ì‹œì„¤ì—ì„œ ì œì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤\"], \"ingredients\": []}\n"
     ]
    }
   ],
   "source": [
    "# --- í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ---\n",
    "if __name__ == \"__main__\":\n",
    "    my_test_image_file = \"data/ê¹€ê´‘ë¬´_121.jpg\"  # í•„ìš”í•˜ë©´ êµì²´\n",
    "    test_input = {\n",
    "        \"image_path\": my_test_image_file,\n",
    "        \"raw_ocr_text\": \"\",\n",
    "        \"ingredients_to_check\": deque(),\n",
    "        \"current_ingredient\": \"\",\n",
    "        \"rag_result\": {\"confidence\": 0.0, \"found_allergen\": \"ì—†ìŒ\", \"method\":\"none\"},\n",
    "        \"final_allergens\": set(),\n",
    "        \"final_output_json\": \"\",\n",
    "        # [ADDED defaults]\n",
    "        \"ingredients_from_section\": [],\n",
    "        \"declared_allergens\": [],\n",
    "        \"coi_phrases\": [],\n",
    "        \"per_ingredient_results\": [],\n",
    "        \"current_raw_ingredient\": \"\"\n",
    "    }\n",
    "    final_state = app.invoke(test_input, {\"recursion_limit\": 100})\n",
    "    print(\"\\n=== ìµœì¢… ë°˜í™˜ JSON ===\")\n",
    "    print(final_state.get(\"final_output_json\",\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
